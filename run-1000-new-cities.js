#!/usr/bin/env node

/**
 * Run Scraper for 1000 NEW Cities
 * Finds cities that haven't been processed yet and scrapes exactly 1000 of them
 * with built-in duplicate prevention for future batch runs
 */

require('dotenv').config();
const fs = require('fs');
const csv = require('csv-parser');
const ScraperFactory = require('./scrapers/modules/factory/scraper-factory');
const SupabaseClient = require('./database/supabase-client');

class Cities1000NewRunner {
    constructor() {
        this.factory = new ScraperFactory();
        this.db = new SupabaseClient();
        this.scraper = null;
        this.scraperId = null;
        this.config = null;
        this.targetCityCount = 1000;
    }

    /**
     * Get all cities from CSV
     */
    async loadAllCities() {
        const csvFile = 'utils/Postleitzahlen Deutschland.csv';
        
        return new Promise((resolve, reject) => {
            const cities = [];
            
            if (!fs.existsSync(csvFile)) {
                reject(new Error(`PLZ CSV file not found: ${csvFile}`));
                return;
            }

            console.log(`üìñ Loading all cities from ${csvFile}...`);

            fs.createReadStream(csvFile)
                .pipe(csv({ separator: ';' }))
                .on('data', (row) => {
                    const cityName = row['PLZ Name (short)'] || row.Name || row.Ort;
                    const plz = row['Postleitzahl / Post code'] || row.PLZ || row.plz;
                    const geoPoint = row['geo_point_2d'];

                    if (cityName && plz) {
                        const city = {
                            originalName: cityName,
                            cityName: cityName,
                            normalizedName: this.extractCityName(cityName),
                            plz: plz.toString()
                        };

                        // Add coordinates if available
                        if (geoPoint) {
                            const coords = geoPoint.split(',');
                            if (coords.length === 2) {
                                city.latitude = parseFloat(coords[0].trim());
                                city.longitude = parseFloat(coords[1].trim());
                            }
                        }

                        cities.push(city);
                    }
                })
                .on('end', () => {
                    console.log(`‚úÖ Loaded ${cities.length} total cities from CSV`);
                    resolve(cities);
                })
                .on('error', reject);
        });
    }

    /**
     * Get existing PLZs from database for current month
     */
    async getExistingPLZs() {
        try {
            const currentMonth = new Date().toISOString().slice(0, 7) + '-01';
            console.log(`üîç Checking existing PLZs in database for ${currentMonth}...`);
            
            const { data, error } = await this.db.supabase
                .from('monthly_electricity_prices')
                .select('plz')
                .eq('data_month', currentMonth);

            if (error) throw error;

            const existingPLZs = new Set(data.map(row => row.plz));
            console.log(`üìä Found ${existingPLZs.size} cities already processed this month`);
            return existingPLZs;
        } catch (error) {
            console.warn('‚ö†Ô∏è  Could not check existing PLZs:', error.message);
            return new Set();
        }
    }

    /**
     * Filter cities to get unprocessed ones
     */
    async getUnprocessedCities() {
        const allCities = await this.loadAllCities();
        const existingPLZs = await this.getExistingPLZs();
        
        const unprocessedCities = allCities.filter(city => !existingPLZs.has(city.plz));
        console.log(`üéØ Found ${unprocessedCities.length} unprocessed cities`);
        
        // Take first 1000 unprocessed cities
        const citiesToProcess = unprocessedCities.slice(0, this.targetCityCount);
        console.log(`üìã Selected ${citiesToProcess.length} cities for processing (target: ${this.targetCityCount})`);
        
        return citiesToProcess;
    }

    /**
     * Extract clean city name from PLZ format
     */
    extractCityName(fullName) {
        // Extract city name (first part before comma if exists)
        return fullName.split(',')[0].trim()
            .replace(/√§/g, 'ae').replace(/√Ñ/g, 'ae')
            .replace(/√∂/g, 'oe').replace(/√ñ/g, 'oe')
            .replace(/√º/g, 'ue').replace(/√ú/g, 'ue')
            .replace(/√ü/g, 'ss')
            .replace(/\s+/g, '-')
            .replace(/[^a-zA-Z0-9\-]/g, '')
            .toLowerCase();
    }

    /**
     * Initialize the modular scraper with optimized settings
     */
    async initializeScraper() {
        try {
            console.log('üèóÔ∏è  Initializing modular scraper for NEW cities...');

            const scraperOptions = {
                source: 'stromauskunft',
                storage: 'supabase',
                enableGeographicCompletion: true,
                config: {
                    // Optimize for batch processing
                    delays: {
                        betweenRequests: parseInt(process.env.SCRAPER_DELAY) || 2000, // 2 second delay (respectful)
                        batchPause: 10000,          // 10 seconds between batches
                        maxRetries: 2
                    },
                    batching: {
                        enabled: true,
                        totalBatches: 5,            // 5 batches of ~200 cities each
                        autoProgress: false,        // Pause between batches for safety
                        stateSaveInterval: 10       // Save state every 10 cities
                    },
                    database: {
                        enableSessionTracking: true,
                        autoMonthDetection: true,
                        duplicateHandling: 'skip',  // Skip duplicates automatically
                        batchingOptimizations: {
                            enableBatchStorage: true,
                            batchStorageSize: 50,
                            enableBatchErrorLogging: true,
                            batchErrorSize: 25,
                            enableBulkDuplicateCheck: true // Check all PLZs for duplicates at start
                        }
                    },
                    quality: {
                        enableOutlierDetection: true,
                        enablePriceValidation: true,
                        enableGeographicFallback: false // Disable for first run
                    },
                    logging: {
                        level: 'info',
                        enableDetailedScraping: process.env.ENABLE_SCRAPING_LOGS === 'true',
                        enableProgressReports: true
                    }
                }
            };

            const result = await this.factory.createImprovedScraper(scraperOptions);
            this.scraper = result.scraper;
            this.scraperId = result.scraperId;
            this.config = result.config;

            console.log('‚úÖ Modular scraper initialized with duplicate prevention');
            console.log(`üìù Session ID: ${this.scraperId}`);

        } catch (error) {
            throw new Error(`Failed to initialize scraper: ${error.message}`);
        }
    }

    /**
     * Run the scraper for 1000 NEW cities
     */
    async run() {
        try {
            console.log('üöÄ Starting 1000 NEW Cities Scraping Session');
            console.log('==========================================\n');

            // 1. Test database connection
            const connectionOk = await this.db.testConnection();
            if (!connectionOk) {
                throw new Error('Database connection failed');
            }

            // 2. Get unprocessed cities
            const cities = await this.getUnprocessedCities();

            if (cities.length === 0) {
                console.log('üéâ All cities have been processed! No new cities to scrape.');
                console.log('üí° If you want to re-scrape existing cities, use the --force option.');
                return;
            }

            // 3. Initialize scraper
            await this.initializeScraper();

            // 4. Show scraping plan
            const delay = parseInt(process.env.SCRAPER_DELAY) || 2000;
            const estimatedTime = Math.ceil(cities.length * delay / 1000 / 60);
            
            console.log('\nüìã SCRAPING PLAN:');
            console.log(`   ‚Ä¢ NEW cities to process: ${cities.length}`);
            console.log(`   ‚Ä¢ Batches: 5 (${Math.ceil(cities.length/5)} cities each)`);
            console.log(`   ‚Ä¢ Delay between requests: ${delay}ms`);
            console.log(`   ‚Ä¢ Estimated total time: ${estimatedTime} minutes`);
            console.log(`   ‚Ä¢ Duplicate prevention: ENABLED`);
            console.log(`   ‚Ä¢ Database storage: ENABLED`);
            console.log(`   ‚Ä¢ Session tracking: ENABLED`);

            console.log('\nüéØ DUPLICATE PREVENTION:');
            console.log('   ‚Ä¢ Only unprocessed cities will be scraped');
            console.log('   ‚Ä¢ Database checked before processing starts');
            console.log('   ‚Ä¢ Future runs will automatically skip these cities');
            console.log('   ‚Ä¢ State is saved every 10 cities for resumability');

            // 5. Execute scraping
            console.log('\nüöÄ Starting scraping workflow...\n');

            const result = await this.scraper.scrapeElectricityPrices(cities, {
                skipExistingData: false,    // We've already filtered duplicates
                targetMonth: null           // Use current month
            });

            console.log('\nüéâ 1000 NEW Cities Scraping Completed!');
            this.printFinalSummary(cities.length);

            return result;

        } catch (error) {
            console.error('üí• Fatal error:', error.message);
            if (process.env.NODE_ENV === 'development') {
                console.error('Stack trace:', error.stack);
            }
            throw error;
        } finally {
            await this.cleanup();
        }
    }

    /**
     * Print final summary
     */
    printFinalSummary(actualCitiesProcessed) {
        console.log('\nüìä === BATCH RUN SUMMARY ===');
        console.log(`   Target cities: ${this.targetCityCount}`);
        console.log(`   Actual new cities processed: ${actualCitiesProcessed}`);
        console.log(`   Session ID: ${this.scraperId}`);
        console.log(`   Month: ${new Date().toISOString().slice(0, 7)}`);
        console.log('\n‚úÖ Next Steps:');
        console.log('   ‚Ä¢ Check database for results');
        console.log('   ‚Ä¢ Run again with same command for next batch of new cities');
        console.log('   ‚Ä¢ System will automatically skip already processed cities');
        console.log('\nüìÅ Database Tables:');
        console.log('   ‚Ä¢ monthly_electricity_prices: Main price data');
        console.log('   ‚Ä¢ scraping_sessions: Session tracking');
        console.log('   ‚Ä¢ scraping_errors: Error details');
        console.log('\nüîÑ Progress Tracking:');
        console.log('   ‚Ä¢ Each run processes only NEW cities');
        console.log('   ‚Ä¢ Perfect for daily/weekly batch processing');
        console.log('   ‚Ä¢ No risk of duplicate work');
    }

    /**
     * Cleanup resources
     */
    async cleanup() {
        try {
            if (this.scraper && typeof this.scraper.cleanup === 'function') {
                await this.scraper.cleanup();
            }
        } catch (error) {
            console.warn('‚ö†Ô∏è  Cleanup warning:', error.message);
        }
    }
}

// Main execution
async function main() {
    const runner = new Cities1000NewRunner();
    
    try {
        await runner.run();
        console.log('\n‚úÖ Script completed successfully!');
        process.exit(0);
    } catch (error) {
        console.error('\n‚ùå Script failed:', error.message);
        process.exit(1);
    }
}

// Run if executed directly
if (require.main === module) {
    main();
}

module.exports = Cities1000NewRunner; 